{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "> A catalogue of not so deep ideas in Deep Learning.\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Research]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning is a collection of techniques for finding functions that can approximate arbitrary input-output mappings, while capturing enough structure of the problem to be able to use them in practical applicatons.language-translation systems,Image classification,Movie Recommendation systems are Some notable applications where they have become defacto-choice. This is by no means an exhaustive treatment of the field. Here I provide concise summaries,followed by a simple implementation of some of the most interesting ideas in the field. I believe that many things in the field are unnecessarily complicated by lengthy treatment where a readable code and short explanation will suffice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note` : This is not intended to be the first introduction to deep learning. Here I wanted to succintly catalogue some the latest advancements in the field. But, respecting tradition the first module starts from the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many deep learning models follow a simple recipe:\n",
    "\n",
    "    1. Gather the data.\n",
    "    2. Define learnable parameters. And specify how they will interact with the data.(architecture)\n",
    "    3. Define a loss function to minimize.\n",
    "    4. Adjust the parameters until satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a linear regression model using gradient-descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will see how we can perform all the above steps starting with the most barebones implementation. Note that the procedure outlined here is general purpose - meaning the way we adjust `parameters` is going to remain same irrecpective of the modality of the data, details of the loss function or the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Gather the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some fake data.Let's assume that the data is coming from $y = 2*x1 - 4.2*x2 + 1 + noise(measurement error)$. This can be more succintly represented in vector notation :\n",
    "$$y = \\begin{bmatrix} x1 \\\\ x2 \\end{bmatrix} . \\begin{bmatrix} 2 \\\\ -4.2 \\end{bmatrix} + 1$$\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_data(*params,const=None,rows=1000):\n",
    "    #number of features in the input\n",
    "    dim = len(params)\n",
    "    x = np.random.normal(0,0.3,(rows,dim))\n",
    "    y = x@np.array([params]).T\n",
    "    if const:\n",
    "        y += np.array([const])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_data(2,-4.2,const=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000, 1))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Define learnable parameters. And specify how they will interact with the data.(architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aim to learn the right coefficients to approximate the data generation process. First let's look at some code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a random guess that respects the sanctity of the data.i.e our inputs are of dimension 1000*2 \n",
    "# outputs are 1000*1. Multiplying inputs by a 2*1 matrix(weights) and adding a constant(bias) is the simplest way\n",
    "# to ensure an output of 1000*1. \n",
    "\n",
    "# initial guess\n",
    "init_weights = np.array([[0.,-1.]]) #shape -> 1*2\n",
    "init_bias = np.array([0.])\n",
    "\n",
    "#expected output\n",
    "def give_expected_output(inpt,weights,bias):\n",
    "    return ((inpt@weights.T) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = give_expected_output(x,init_weights,init_bias)#shape -> 1000*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(out,expected_out):\n",
    "    return np.mean((expected_out - out)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3825763471307235"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_error(out,y) # IF WE CAN DRIVE THIS NUMBER DOWN TO ZERO VIA A GENERAL PURPOSE PROCESS,WE ARE GOOD TO GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grads(weights,bias,x,y,loss_func='squared_loss'):\n",
    "    if loss_func == 'squared_loss':\n",
    "        weights_grad = 2*np.mean((x@weights.T + bias - y)*weights)\n",
    "        bias_grad = 2*np.mean((x@weights.T + bias - y))\n",
    "    else:\n",
    "        print(\"Sorry I'm not yet scalable enough for arbitrary loss functions\")\n",
    "    return weights_grad,bias_grad\n",
    "        \n",
    "\n",
    "\n",
    "grad_init_weights,grad_bias = get_grads(init_weights,init_bias,x,y,loss_func = 'squared_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(x,y,init_weights,init_bias,loss_func,lr=0.001,epochs=5000):\n",
    "    out = give_expected_output(x,init_weights,init_bias)\n",
    "    error = loss_func(out,y)\n",
    "    #print(f'initial error, epoch 0: {error}')\n",
    "    errors = [error]\n",
    "    pres_lr = lr\n",
    "    for i in range(epochs):\n",
    "        weight_grad,bias_grad = get_grads(init_weights,init_bias,x,y)\n",
    "        init_weights -= weight_grad*pres_lr\n",
    "        init_bias -= bias_grad*pres_lr\n",
    "        out = give_expected_output(x,init_weights,init_bias)\n",
    "        error = loss_func(out,y)\n",
    "        if np.mean(weight_grad)<0.0001:\n",
    "            pres_lr = pres_lr*2\n",
    "        errors.append(error)\n",
    "    return errors,init_weights,init_bias\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors,final_weights,final_bias = learn(x,y,init_weights,init_bias,get_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37afe90190>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.89305539, -1.89305539]]), array([1.02516621]))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weights,final_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above code what happens if 'lr' is not dynamically adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we know the parameters of the model `[2,-4.2]`. Our task is to learn them by just using input-output mappings `(x,y)`. Ideally we even don't have to extract the orginal parameters but only be able to reduce some predefined loss. But for now, let's just see if we could extract the orginal parameters using the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: From scratch - implement backprop in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From scratch using pytorch\n",
    "\n",
    "def model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More about pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pytorch to building more flexible architecure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Good ideas to know\n",
    "\n",
    "DropOut : While training some of the hidden layers can be randomly put to zero. This forces our network to learn more robust representations. Dropout can also break symmetry.\n",
    "\n",
    "Break Symmetry : Initialize weights randomly to break symmetry.\n",
    "\n",
    "Regularization methods: Weight Decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read [Convolutions Arthmetic](https://arxiv.org/pdf/1603.07285.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
