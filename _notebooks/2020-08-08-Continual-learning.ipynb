{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual Learning\n",
    "> A tutorial Survey\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Research,Artificial General Intelligence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The objective of this work is to provide a coherent picture of `Continual Learning` in the context of Neural Networks. I hope that this would serve as a launch pad for further investigations of the reader. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual Learning\n",
    "\n",
    "Modern Deep Learning systems,in general, deal exclusively with i.i.d. data. If our grand objective is to build General Intelligence,then it is mandatory for a single system to learn multiple tasks. Here , We will start with the general setting of continual learning and then begin to investigate how various features of the problem are solved by current methods.\n",
    "\n",
    "> Note: None of the known methods satisfactorily solve Continual Learning problem in it's General Setting.\n",
    "\n",
    "```\n",
    "Continual Learning : The General Setting\n",
    "\n",
    "Optimize a defined loss function under Infinite Stream of Data,without any explicit distinction between tasks. \n",
    "\n",
    "Note : Here 'task' is artificially introduced to represent variation in data distribution and even loss function.\n",
    "\n",
    "```\n",
    "\n",
    "The following are some of the desirable features of the learning scheme {% fn 1 %}:\n",
    "\n",
    "1. `Fixed Memory` : Memory requirements cannot grow with each additional task.\n",
    "\n",
    "2. `No Task Boundary` : Learn from the input data without explicitly defining task boundary increases the flexibility of the method and also reflects real-world setting.\n",
    "\n",
    "3. `Online Learning` :  No offline storing of data.(i.e training with large batches for multiple epochs)\n",
    "\n",
    "4. `Forward Transfer` : Previous tasks should ease the learning on new tasks.\n",
    "\n",
    "5. `Backward Transfer` : Upon Learning future tasks, performance on correspondingly related past tasks should improve.\n",
    "\n",
    "6. `Problem Agnostic` : Should be flexible enough to work with different loss functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Important: Humans do not exactly operate in the General setting of 'Continual Learning'. We often have local control over the stream of tasks. We decide,apriori the sequence of tasks to perform in order to reach a desired goal. We also assign ourselves tasks(thus access to task labels) in order to optimize our goals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implicit in the above definition,we expect the learning procedure to learn flexible representations. Traditional machine learning paradigm aims to learn a specifit task - machine translation,Image recognition,Speech synthesis - end to end,often from scratch. This is facilitated by training on large amounts of data,specific to the task.Consider Classical MNIST and CIFAR-10 Datesets,that have propelled progress in Computer vision. Each of these have 60,000 Images split equally between ten classes. This is in sharp contrast to how a human experiences learning. Our learning involves learning large number of classes,with few examples from each class.(say 6000 classes with 10 examples for each). Thus,our learning procedure is optimized for this setting and we are forced to learn concepts and abstractions that let us learn quickly and efficiently with less data. Later in this section,we will see techniques that tries to alleviate this problem in modern neural networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider three scenarios,which will better help us to better parse the existing literature in the field.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$e^{i\\pi} + 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{i=0}^n i^2 = \\frac{(n^2+n)(2n+1)}{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/deep-learning.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approaches taken can be broadly categorized into three groups {% fn 2 %}:\n",
    "\n",
    "\n",
    "1. Modify the Update Rule\n",
    "\n",
    "2. Replay methods\n",
    "\n",
    "3. Use Semi-distributed representations\n",
    "\n",
    "4. Meta-Approaches\n",
    "\n",
    "Here we will cover some representative works from each of the above categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modify the Update Rule \n",
    "\n",
    "Instead of updating all the weights on a new task, the most important weights are retained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Meta-Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, We will try to understand the various incarnations of these approaches and finally conclude with some recent works that try to leverage Meta-Approaches for Continual Learning.\n",
    "\n",
    "Meta-Learning is a general paradigm that aims to condition the learning rule itself based on pre-defined properties of the learned representations. This will become clear when we see concrete examples. But,for our task of continual learning, Meta-Approaches offer a way away from hand-engineered approaches to learning-based solutions. Let us explore few foundational works in this field,before we see a concrete example for Continual Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Note: I will not cover the complete spectrum of Meta-Learning approaches,just enough to appreciate how this paradigm allows for a more flexible approach towards solving Continual Learning. But,for a good strating point check [Lil'Log's Blog](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL-AGNOSTIC META- LEARNING (MAML) {% fn 3 %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation :\n",
    "\n",
    "T : The task, corresponds to the objective or loss function,domain,environment.\n",
    "\n",
    "p(T): The distribution of tasks from which a new task is sampled.\n",
    "\n",
    "f<sub>&theta;</sub>   : A model(neural net) parametrized by $\\theta$ \n",
    "\n",
    "{T<sub>i</sub>} ~ p(T) : Tasks used for meta training\n",
    "\n",
    "{T<sub>j</sub>} ~ p(T) : Tasks used for meta testing\n",
    "\n",
    "{D<sub>$T_i$</sub>} : Meta-training set\n",
    "\n",
    "{D<sub>$T_j$</sub>} : Meta-testing set\n",
    "\n",
    "\n",
    "{D<sub>T</sub><sup>tr</sup>} : Traning data for task T\n",
    "\n",
    "{D<sub>T</sub><sup>test</sup>} : Test data for task T\n",
    "\n",
    "L<sub>T<sub>i</sub></sub> : Loss or feedback from the sampled task T<sub>i</sub>\n",
    "\n",
    "\n",
    "Given that we want our model to quickly adapt to a wide range of tasks, can we incorporate this inductive bias  explicitly into our training ?\n",
    "\n",
    "\n",
    "####  PROBLEM STATEMENT :\n",
    "\n",
    "Learn the weights of a neural net that can quickly learn to perform well on a new task.\n",
    "\n",
    "#### Method :\n",
    "\n",
    "The intuition is to learn the right set of initial parameters that which upon few gradient steps on a new task,would result in good performance.\n",
    "\n",
    "Consider a task T<sub>i</sub> drawn out of task distribution p(T). Now, from this T<sub>i</sub> we can sample training dataset D<sub>i</sub><sup>tr</sup>,the loss/feedback on which is given by L<sub>T<sub>i</sub></sub>. This loss is parameterized by f<sub>&theta;</sub>. Suppose we take few gradient steps on this $\\theta$ to give $\\phi$. The error on test data set ,D<sub>i</sub><sup>test</sup> sampled from T<sub>i</sub>,acts as training signal to update orginal f<sub>&theta;</sub>. \n",
    "\n",
    "What makes this process different from traditional training of neural networks is that the gradient is taken over meta-parameters $\\phi$ through $\\theta$. Consider the case of taking one gradient over L<sub>T<sub>i</sub></sub> to arrive at $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\phi_i  = \\theta - \\alpha \\nabla_\\theta \\mathscr{L}(\\theta,D_{T_i}^{tr})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,the loss on $\\phi$<sub>i</sub> (taken on  $ {D_{T_i}^{test}} $ ) is backpropagated through $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ min_{\\theta} \\Sigma_{{T_i}\\thicksim p(T)} L(\\phi_i,D_{T_i}^{test}) = min_{\\theta} \\Sigma_{{T_i}\\thicksim p(T)} \\mathscr{L}(\\theta - \\alpha \\nabla_\\theta \\mathscr{L}(\\theta,D_{T_i}^{tr}),D_{T_i}^{test}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha : Learning rate(hyper-parameter)$\n",
    "\n",
    "\n",
    "Note that the meta-optimization is performed over the model parameters $\\theta$, whereas the objective is computed using the updated model parameters $\\phi$. In effect, the method aims to optimize the model parameters such that one or a small number of gradient steps on a new task will produce maximally effective behavior on that task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/maml.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We will see how this approach can be applied to `Continual learning` by just tweaking the problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathscr{L}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here is a footnote {% fn 1 %}.\n",
    "And another {% fn 2 %}\n",
    "{{ 'This is the footnote.' | fndetail: 1 }}\n",
    "{{ 'This is the other footnote. You can even have a [link](https://arxiv.org/abs/1905.12588)!' | fndetail: 2 }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ '[arXiv:1909.08383](https://arxiv.org/abs/1909.08383)!' | fndetail: 1 }}\n",
    "{{ '[arXiv:1905.12588](https://arxiv.org/abs/1905.12588)!' | fndetail: 2 }}\n",
    "{{ '[arXiv:1703.03400](https://arxiv.org/abs/1703.03400)!' | fndetail: 3 }}\n",
    "{{ '[arXiv:1905.12588](https://arxiv.org/abs/1905.12588)!' | fndetail: 4 }}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
